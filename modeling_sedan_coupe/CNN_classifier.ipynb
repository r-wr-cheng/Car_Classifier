{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "#tf.enable_eager_execution()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv('/home/ec2-user/training_data_meta.csv')\n",
    "\n",
    "#Join cleaned class data with training metadata\n",
    "\n",
    "class_data = pd.read_csv('/home/ec2-user/stanford_labels_cleaned.csv')\n",
    "\n",
    "meta_data = pd.merge(meta_data, class_data, on = 'class', how = 'left')\n",
    "\n",
    "meta_data = meta_data.loc[meta_data['Body Type'].isin(['Coupe', 'Sedan'])].copy()\n",
    "\n",
    "meta_data['is_sedan_target'] = (meta_data['Body Type'] == 'Sedan').astype(int)\n",
    "\n",
    "image_dict = p.load(open('/home/ec2-user/scaled_bounded_grayscale_dict.p', 'rb'))\n",
    "\n",
    "training_data = []\n",
    "for i in meta_data[['is_sedan_target', 'fname']].iterrows():\n",
    "    row = [i[1]['is_sedan_target']]\n",
    "    row.extend(image_dict[i[1]['fname']].flatten())\n",
    "    training_data.append(row)\n",
    "\n",
    "training_data = np.array(training_data).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_data[:,1:], \n",
    "                                                    training_data[:,0], \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=420)\n",
    "\n",
    "y_train = y_train.astype('int32')\n",
    "y_test = y_test.astype('int32')\n",
    "\n",
    "negatives = []\n",
    "for ind, elem in enumerate(y_train):\n",
    "    if elem == 0:\n",
    "        negatives.append(ind)\n",
    "np.random.shuffle(negatives)\n",
    "\n",
    "neg_dupe_target = 2 * y_train.sum() - y_train.shape[0]\n",
    "\n",
    "X_train = np.concatenate([X_train, X_train[negatives[0:neg_dupe_target],:]],\n",
    "                         axis = 0\n",
    "                        )\n",
    "y_train = np.concatenate([y_train, y_train[negatives[0:neg_dupe_target]]],\n",
    "                         axis = 0\n",
    "                        )\n",
    "\n",
    "y_train = np.concatenate([1 - y_train.reshape(-1,1), y_train.reshape(-1,1)], axis = 1)\n",
    "y_test = np.concatenate([1 - y_test.reshape(-1,1), y_test.reshape(-1,1)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    if type(features) is dict:\n",
    "        features = features['input']\n",
    "    #Define model architecture\n",
    "    \n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    input_layer = tf.reshape(features, [-1, 200, 200, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Computes 32 features using a 3x3 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 200, 200, 1]\n",
    "    # Output Tensor Shape: [batch_size, 200, 200, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 200, 200, 32]\n",
    "    # Output Tensor Shape: [batch_size, 100, 100, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Computes 64 features using a 3x3 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 100, 100, 32]\n",
    "    # Output Tensor Shape: [batch_size, 100, 100, 64]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 100, 100, 64]\n",
    "    # Output Tensor Shape: [batch_size, 50, 50, 64]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "      inputs=pool2,\n",
    "      filters=64,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #3\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 50, 50, 64]\n",
    "    # Output Tensor Shape: [batch_size, 25, 25, 64]\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 25, 25, 64]\n",
    "    # Output Tensor Shape: [batch_size, 25 * 25 * 64]\n",
    "    pool3_flat = tf.reshape(pool3, [-1, 25 * 25 * 64])\n",
    "\n",
    "    # Dense Layer\n",
    "    # Densely connected layer with 256 neurons\n",
    "    # Input Tensor Shape: [batch_size, 25 * 25 * 64]\n",
    "    # Output Tensor Shape: [batch_size, 256]\n",
    "    dense = tf.layers.dense(inputs=pool3_flat, units=256, activation=tf.nn.relu)\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.5, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=2)\n",
    "    \n",
    "    #Predict Op\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            # Generate predictions (for PREDICT and EVAL mode)\n",
    "            \"classes\": tf.argmax(input=logits, axis=1),\n",
    "            # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "            # `logging_hook`.\n",
    "            \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\"),\n",
    "            \"logits\" : logits\n",
    "            \n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #Define model outputs\n",
    "        # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels[:,1], logits=logits)\n",
    "        \n",
    "        logging_hook = tf.train.LoggingTensorHook(\n",
    "            {\"loss\" : loss,\n",
    "            },\n",
    "            every_n_iter=10)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss, train_op=train_op, training_hooks = [logging_hook])\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        #Define model outputs\n",
    "        # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels[:,1], logits=logits)\n",
    "        \n",
    "        predictions = {\n",
    "          # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "          # `logging_hook`.\n",
    "          \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "        }\n",
    "        #swap this for AUROC?\n",
    "        eval_metric_ops = {\n",
    "          \"eval_accuracy\": tf.metrics.auc(\n",
    "              labels=labels, predictions=predictions[\"probabilities\"])}\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "          mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/home/ec2-user/convnet_model', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 32\n",
      "inter_op_parallelism_threads: 32\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f93f444fb00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "session_config = tf.ConfigProto(\n",
    "      inter_op_parallelism_threads=32,\n",
    "      intra_op_parallelism_threads=32,\n",
    "      )\n",
    "\n",
    "config = tf.estimator.RunConfig(session_config = session_config,\n",
    "                                log_step_count_steps = 10,\n",
    "                                save_summary_steps = 10\n",
    "                               )\n",
    "\n",
    "# Create the Estimator\n",
    "car_classifier = tf.estimator.Estimator(\n",
    "  model_fn=cnn_model_fn, model_dir=\"/home/ec2-user/convnet_model\", config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom input function using training_image_processor with tf.data.Dataset\n",
    "def image_processor_train_input_fn(image_processor, X_train, y_train, batch_size):\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator = lambda : image_processor.flow(X_train.reshape((X_train.shape[0], 200, 200, 1)), \n",
    "                                                  y_train, batch_size, shuffle = True), \n",
    "        output_types = (np.float32, np.int32))\n",
    "    \n",
    "    dataset = dataset.shuffle(512).repeat()\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def image_processor_eval_input_fn(X_test, y_test, batch_size):\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_test.astype('float32') / 255.0, \n",
    "                                                  y_test.astype('int32')))\n",
    "        \n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "#Shearing, no zooming\n",
    "training_image_processor = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    shear_range=15,\n",
    "    horizontal_flip=True,\n",
    "    data_format = 'channels_last',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.3248356, step = 2001\n",
      "INFO:tensorflow:loss = 0.3248356\n",
      "INFO:tensorflow:global_step/sec: 0.253579\n",
      "INFO:tensorflow:loss = 0.3441033, step = 2011 (39.437 sec)\n",
      "INFO:tensorflow:loss = 0.3441033 (39.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302291\n",
      "INFO:tensorflow:loss = 0.2703493, step = 2021 (33.080 sec)\n",
      "INFO:tensorflow:loss = 0.2703493 (33.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.305158\n",
      "INFO:tensorflow:loss = 0.41520917, step = 2031 (32.770 sec)\n",
      "INFO:tensorflow:loss = 0.41520917 (32.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.307353\n",
      "INFO:tensorflow:loss = 0.21544191, step = 2041 (32.536 sec)\n",
      "INFO:tensorflow:loss = 0.21544191 (32.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.294563\n",
      "INFO:tensorflow:loss = 0.33473867, step = 2051 (33.948 sec)\n",
      "INFO:tensorflow:loss = 0.33473867 (33.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.293682\n",
      "INFO:tensorflow:loss = 0.24005482, step = 2061 (34.051 sec)\n",
      "INFO:tensorflow:loss = 0.24005482 (34.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.293678\n",
      "INFO:tensorflow:loss = 0.35831976, step = 2071 (34.051 sec)\n",
      "INFO:tensorflow:loss = 0.35831976 (34.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.306003\n",
      "INFO:tensorflow:loss = 0.2576354, step = 2081 (32.679 sec)\n",
      "INFO:tensorflow:loss = 0.2576354 (32.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.296576\n",
      "INFO:tensorflow:loss = 0.2389964, step = 2091 (33.718 sec)\n",
      "INFO:tensorflow:loss = 0.2389964 (33.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.294346\n",
      "INFO:tensorflow:loss = 0.2477074, step = 2101 (33.974 sec)\n",
      "INFO:tensorflow:loss = 0.2477074 (33.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.296427\n",
      "INFO:tensorflow:loss = 0.27468842, step = 2111 (33.735 sec)\n",
      "INFO:tensorflow:loss = 0.27468842 (33.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295007\n",
      "INFO:tensorflow:loss = 0.27437282, step = 2121 (33.898 sec)\n",
      "INFO:tensorflow:loss = 0.27437282 (33.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.293847\n",
      "INFO:tensorflow:loss = 0.26806203, step = 2131 (34.031 sec)\n",
      "INFO:tensorflow:loss = 0.26806203 (34.031 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2132 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.308027\n",
      "INFO:tensorflow:loss = 0.26127568, step = 2141 (32.465 sec)\n",
      "INFO:tensorflow:loss = 0.26127568 (32.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.294466\n",
      "INFO:tensorflow:loss = 0.2576074, step = 2151 (33.960 sec)\n",
      "INFO:tensorflow:loss = 0.2576074 (33.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.308349\n",
      "INFO:tensorflow:loss = 0.26169705, step = 2161 (32.431 sec)\n",
      "INFO:tensorflow:loss = 0.26169705 (32.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.293253\n",
      "INFO:tensorflow:loss = 0.2652046, step = 2171 (34.100 sec)\n",
      "INFO:tensorflow:loss = 0.2652046 (34.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295316\n",
      "INFO:tensorflow:loss = 0.2162199, step = 2181 (33.862 sec)\n",
      "INFO:tensorflow:loss = 0.2162199 (33.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.307227\n",
      "INFO:tensorflow:loss = 0.26718462, step = 2191 (32.549 sec)\n",
      "INFO:tensorflow:loss = 0.26718462 (32.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.306381\n",
      "INFO:tensorflow:loss = 0.2177133, step = 2201 (32.639 sec)\n",
      "INFO:tensorflow:loss = 0.2177133 (32.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.294287\n",
      "INFO:tensorflow:loss = 0.28518435, step = 2211 (33.980 sec)\n",
      "INFO:tensorflow:loss = 0.28518435 (33.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.297519\n",
      "INFO:tensorflow:loss = 0.24028282, step = 2221 (33.611 sec)\n",
      "INFO:tensorflow:loss = 0.24028282 (33.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.299322\n",
      "INFO:tensorflow:loss = 0.32084364, step = 2231 (33.409 sec)\n",
      "INFO:tensorflow:loss = 0.32084364 (33.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295507\n",
      "INFO:tensorflow:loss = 0.25198135, step = 2241 (33.840 sec)\n",
      "INFO:tensorflow:loss = 0.25198135 (33.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.296246\n",
      "INFO:tensorflow:loss = 0.27786398, step = 2251 (33.756 sec)\n",
      "INFO:tensorflow:loss = 0.27786398 (33.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.304561\n",
      "INFO:tensorflow:loss = 0.2755053, step = 2261 (32.834 sec)\n",
      "INFO:tensorflow:loss = 0.2755053 (32.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.293613\n",
      "INFO:tensorflow:loss = 0.23705488, step = 2271 (34.058 sec)\n",
      "INFO:tensorflow:loss = 0.23705488 (34.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295971\n",
      "INFO:tensorflow:loss = 0.31893545, step = 2281 (33.787 sec)\n",
      "INFO:tensorflow:loss = 0.31893545 (33.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.309242\n",
      "INFO:tensorflow:loss = 0.31451097, step = 2291 (32.337 sec)\n",
      "INFO:tensorflow:loss = 0.31451097 (32.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.296955\n",
      "INFO:tensorflow:loss = 0.19440028, step = 2301 (33.675 sec)\n",
      "INFO:tensorflow:loss = 0.19440028 (33.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.294913\n",
      "INFO:tensorflow:loss = 0.27756914, step = 2311 (33.908 sec)\n",
      "INFO:tensorflow:loss = 0.27756914 (33.908 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2312 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.331306\n",
      "INFO:tensorflow:loss = 0.20722322, step = 2321 (30.184 sec)\n",
      "INFO:tensorflow:loss = 0.20722322 (30.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.298777\n",
      "INFO:tensorflow:loss = 0.17003196, step = 2331 (33.470 sec)\n",
      "INFO:tensorflow:loss = 0.17003196 (33.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.299857\n",
      "INFO:tensorflow:loss = 0.1999446, step = 2341 (33.349 sec)\n",
      "INFO:tensorflow:loss = 0.1999446 (33.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295648\n",
      "INFO:tensorflow:loss = 0.36268908, step = 2351 (33.824 sec)\n",
      "INFO:tensorflow:loss = 0.36268908 (33.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.307004\n",
      "INFO:tensorflow:loss = 0.30641028, step = 2361 (32.573 sec)\n",
      "INFO:tensorflow:loss = 0.30641028 (32.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295821\n",
      "INFO:tensorflow:loss = 0.19043761, step = 2371 (33.804 sec)\n",
      "INFO:tensorflow:loss = 0.19043761 (33.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.296372\n",
      "INFO:tensorflow:loss = 0.25069577, step = 2381 (33.741 sec)\n",
      "INFO:tensorflow:loss = 0.25069577 (33.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.297823\n",
      "INFO:tensorflow:loss = 0.26387772, step = 2391 (33.577 sec)\n",
      "INFO:tensorflow:loss = 0.26387772 (33.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.307332\n",
      "INFO:tensorflow:loss = 0.2614727, step = 2401 (32.538 sec)\n",
      "INFO:tensorflow:loss = 0.2614727 (32.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.307956\n",
      "INFO:tensorflow:loss = 0.2794514, step = 2411 (32.472 sec)\n",
      "INFO:tensorflow:loss = 0.2794514 (32.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30712\n",
      "INFO:tensorflow:loss = 0.264459, step = 2421 (32.560 sec)\n",
      "INFO:tensorflow:loss = 0.264459 (32.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.329309\n",
      "INFO:tensorflow:loss = 0.25832742, step = 2431 (30.367 sec)\n",
      "INFO:tensorflow:loss = 0.25832742 (30.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295939\n",
      "INFO:tensorflow:loss = 0.30262348, step = 2441 (33.791 sec)\n",
      "INFO:tensorflow:loss = 0.30262348 (33.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.293842\n",
      "INFO:tensorflow:loss = 0.22739533, step = 2451 (34.032 sec)\n",
      "INFO:tensorflow:loss = 0.22739533 (34.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.304404\n",
      "INFO:tensorflow:loss = 0.24071549, step = 2461 (32.851 sec)\n",
      "INFO:tensorflow:loss = 0.24071549 (32.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.292822\n",
      "INFO:tensorflow:loss = 0.25363553, step = 2471 (34.150 sec)\n",
      "INFO:tensorflow:loss = 0.25363553 (34.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.294798\n",
      "INFO:tensorflow:loss = 0.2587291, step = 2481 (33.922 sec)\n",
      "INFO:tensorflow:loss = 0.2587291 (33.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.304256\n",
      "INFO:tensorflow:loss = 0.21476878, step = 2491 (32.867 sec)\n",
      "INFO:tensorflow:loss = 0.21476878 (32.867 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2494 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.29393\n",
      "INFO:tensorflow:loss = 0.25971445, step = 2501 (34.022 sec)\n",
      "INFO:tensorflow:loss = 0.25971445 (34.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.28851736, step = 2511 (33.891 sec)\n",
      "INFO:tensorflow:loss = 0.28851736 (33.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.296071\n",
      "INFO:tensorflow:loss = 0.25402114, step = 2521 (33.776 sec)\n",
      "INFO:tensorflow:loss = 0.25402114 (33.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.318947\n",
      "INFO:tensorflow:loss = 0.176983, step = 2531 (31.353 sec)\n",
      "INFO:tensorflow:loss = 0.176983 (31.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.303927\n",
      "INFO:tensorflow:loss = 0.28167146, step = 2541 (32.903 sec)\n",
      "INFO:tensorflow:loss = 0.28167146 (32.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.298263\n",
      "INFO:tensorflow:loss = 0.20035866, step = 2551 (33.528 sec)\n",
      "INFO:tensorflow:loss = 0.20035866 (33.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295796\n",
      "INFO:tensorflow:loss = 0.16533354, step = 2561 (33.807 sec)\n",
      "INFO:tensorflow:loss = 0.16533354 (33.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.297268\n",
      "INFO:tensorflow:loss = 0.20754793, step = 2571 (33.640 sec)\n",
      "INFO:tensorflow:loss = 0.20754793 (33.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295934\n",
      "INFO:tensorflow:loss = 0.1752066, step = 2581 (33.791 sec)\n",
      "INFO:tensorflow:loss = 0.1752066 (33.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.306086\n",
      "INFO:tensorflow:loss = 0.25453645, step = 2591 (32.671 sec)\n",
      "INFO:tensorflow:loss = 0.25453645 (32.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295161\n",
      "INFO:tensorflow:loss = 0.2956593, step = 2601 (33.880 sec)\n",
      "INFO:tensorflow:loss = 0.2956593 (33.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.307729\n",
      "INFO:tensorflow:loss = 0.21121503, step = 2611 (32.496 sec)\n",
      "INFO:tensorflow:loss = 0.21121503 (32.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.297424\n",
      "INFO:tensorflow:loss = 0.18043324, step = 2621 (33.622 sec)\n",
      "INFO:tensorflow:loss = 0.18043324 (33.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295379\n",
      "INFO:tensorflow:loss = 0.24768305, step = 2631 (33.855 sec)\n",
      "INFO:tensorflow:loss = 0.24768305 (33.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.298359\n",
      "INFO:tensorflow:loss = 0.20615497, step = 2641 (33.517 sec)\n",
      "INFO:tensorflow:loss = 0.20615497 (33.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.29537\n",
      "INFO:tensorflow:loss = 0.23646915, step = 2651 (33.856 sec)\n",
      "INFO:tensorflow:loss = 0.23646915 (33.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.294097\n",
      "INFO:tensorflow:loss = 0.2214377, step = 2661 (34.002 sec)\n",
      "INFO:tensorflow:loss = 0.2214377 (34.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.307884\n",
      "INFO:tensorflow:loss = 0.27129066, step = 2671 (32.480 sec)\n",
      "INFO:tensorflow:loss = 0.27129066 (32.480 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2674 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.303454\n",
      "INFO:tensorflow:loss = 0.15433624, step = 2681 (32.954 sec)\n",
      "INFO:tensorflow:loss = 0.15433624 (32.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.29633\n",
      "INFO:tensorflow:loss = 0.17627251, step = 2691 (33.746 sec)\n",
      "INFO:tensorflow:loss = 0.17627251 (33.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.295438\n",
      "INFO:tensorflow:loss = 0.3133675, step = 2701 (33.848 sec)\n",
      "INFO:tensorflow:loss = 0.3133675 (33.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.305528\n",
      "INFO:tensorflow:loss = 0.25603896, step = 2711 (32.730 sec)\n",
      "INFO:tensorflow:loss = 0.25603896 (32.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.305562\n",
      "INFO:tensorflow:loss = 0.19183807, step = 2721 (32.727 sec)\n",
      "INFO:tensorflow:loss = 0.19183807 (32.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.308482\n",
      "INFO:tensorflow:loss = 0.23637621, step = 2731 (32.417 sec)\n",
      "INFO:tensorflow:loss = 0.23637621 (32.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.309725\n",
      "INFO:tensorflow:loss = 0.13718778, step = 2741 (32.287 sec)\n",
      "INFO:tensorflow:loss = 0.13718778 (32.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.309216\n",
      "INFO:tensorflow:loss = 0.1622681, step = 2751 (32.340 sec)\n",
      "INFO:tensorflow:loss = 0.1622681 (32.340 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-88df287ddb9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m car_classifier.train(\n\u001b[1;32m      2\u001b[0m       \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimage_processor_train_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_image_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "car_classifier.train(\n",
    "      input_fn=lambda:image_processor_train_input_fn(training_image_processor, X_train, y_train, 128),\n",
    "      steps=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-04T04:43:21Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-2674\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-04-04:43:53\n",
      "INFO:tensorflow:Saving dict for global step 2674: eval_accuracy = 0.9884874, global_step = 2674, loss = 0.13522062\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2674: /home/ec2-user/convnet_model/model.ckpt-2674\n",
      "{'eval_accuracy': 0.9884874, 'loss': 0.13522062, 'global_step': 2674}\n",
      "testing error\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-04T04:43:54Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-2674\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-04-04:44:05\n",
      "INFO:tensorflow:Saving dict for global step 2674: eval_accuracy = 0.8651957, global_step = 2674, loss = 0.6749204\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2674: /home/ec2-user/convnet_model/model.ckpt-2674\n",
      "{'eval_accuracy': 0.8651957, 'loss': 0.6749204, 'global_step': 2674}\n"
     ]
    }
   ],
   "source": [
    "print('training error')\n",
    "eval_results = car_classifier.evaluate(\n",
    "    input_fn=lambda:image_processor_eval_input_fn(X_train, y_train, 32))\n",
    "print(eval_results)\n",
    "\n",
    "print('testing error')\n",
    "eval_results = car_classifier.evaluate(\n",
    "    input_fn=lambda:image_processor_eval_input_fn(X_test, y_test, 32))\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-2674\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = car_classifier.predict(\n",
    "    input_fn=lambda:image_processor_eval_input_fn(X_test, y_test, 32))\n",
    "\n",
    "testing_analysis = []\n",
    "\n",
    "for pred, label in zip(predicted_classes, y_test):\n",
    "    hold = [pred['probabilities'][1], pred['classes'], label[1], pred['logits'][0], pred['logits'][1]]\n",
    "    testing_analysis.append(hold)\n",
    "    \n",
    "testing_analysis = pd.DataFrame(testing_analysis, columns = ['prob', 'class', 'label', 'logit_0', 'logit_1'])\n",
    "testing_analysis['logit_1_decile'] = pd.qcut(testing_analysis.logit_1, 10, labels = False)\n",
    "testing_analysis['logit_0_decile'] = pd.qcut(testing_analysis.logit_0, 10, labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logit_1_decile  label  class\n",
       "0               0      0         95\n",
       "                1      0         14\n",
       "1               0      0         93\n",
       "                1      0         15\n",
       "2               0      0         78\n",
       "                1      0         31\n",
       "3               0      0         69\n",
       "                1      0         39\n",
       "4               0      0         36\n",
       "                       1          8\n",
       "                1      0         42\n",
       "                       1         23\n",
       "5               0      1         37\n",
       "                       0          1\n",
       "                1      1         69\n",
       "                       0          1\n",
       "6               0      1         21\n",
       "                1      1         87\n",
       "7               0      1         15\n",
       "                1      1         94\n",
       "8               0      1          2\n",
       "                1      1        106\n",
       "9               0      1          1\n",
       "                1      1        108\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_analysis.groupby(['logit_1_decile', 'label'])['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logit_0_decile  label  class\n",
       "0               0      1          2\n",
       "                1      1        107\n",
       "1               0      1          6\n",
       "                1      1        102\n",
       "2               0      1         10\n",
       "                1      1         99\n",
       "3               0      1         22\n",
       "                1      1         86\n",
       "4               0      1         28\n",
       "                       0          2\n",
       "                1      1         75\n",
       "                       0          4\n",
       "5               0      0         38\n",
       "                       1         16\n",
       "                1      0         36\n",
       "                       1         18\n",
       "6               0      0         65\n",
       "                1      0         43\n",
       "7               0      0         80\n",
       "                1      0         29\n",
       "8               0      0         92\n",
       "                1      0         16\n",
       "9               0      0         95\n",
       "                1      0         14\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_analysis.groupby(['logit_0_decile', 'label'])['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label  class\n",
       "0      0        372\n",
       "       1         84\n",
       "1      1        487\n",
       "       0        142\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_analysis.groupby('label')['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in testing_analysis.loc[testing_analysis.logit_1_decile == 9].index[0:20]:\n",
    "    plt.figure()\n",
    "    row = testing_analysis.iloc[i]\n",
    "    plt.title('class %f label %f'%(row['class'], row['label']))\n",
    "    imshow(Image.fromarray((X_test[i,:].reshape((200,200))).astype('uint8'), mode = 'L'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUVs and Verts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv('/home/ec2-user/training_data_meta.csv')\n",
    "\n",
    "#Join cleaned class data with training metadata\n",
    "\n",
    "class_data = pd.read_csv('/home/ec2-user/stanford_labels_cleaned.csv')\n",
    "\n",
    "meta_data = pd.merge(meta_data, class_data, on = 'class', how = 'left')\n",
    "\n",
    "meta_data = meta_data.loc[meta_data['Body Type'].isin(['SUV', 'Convertible'\n",
    "                                                      ])].copy()\n",
    "\n",
    "meta_data['is_sedan_target'] = (meta_data['Body Type'] == 'SUV').astype(int)\n",
    "\n",
    "image_dict = p.load(open('/home/ec2-user/scaled_bounded_grayscale_dict.p', 'rb'))\n",
    "\n",
    "oot_data = []\n",
    "for i in meta_data[['is_sedan_target', 'fname']].iterrows():\n",
    "    row = [i[1]['is_sedan_target']]\n",
    "    row.extend(image_dict[i[1]['fname']].flatten())\n",
    "    oot_data.append(row)\n",
    "\n",
    "oot_data = np.array(oot_data).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oot = oot_data[:,1:]\n",
    "\n",
    "y_oot = oot_data[:,0].astype('int32')\n",
    "y_oot = np.concatenate([1 - y_oot.reshape(-1,1), y_oot.reshape(-1,1)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oot error\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-21T15:51:47Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-5653\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-21-15:52:17\n",
      "INFO:tensorflow:Saving dict for global step 5653: eval_accuracy = 0.82551754, global_step = 5653, loss = 0.80654323\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5653: /home/ec2-user/convnet_model/model.ckpt-5653\n",
      "{'eval_accuracy': 0.82551754, 'loss': 0.80654323, 'global_step': 5653}\n"
     ]
    }
   ],
   "source": [
    "print('oot error')\n",
    "eval_results = car_classifier.evaluate(\n",
    "    input_fn=lambda:image_processor_eval_input_fn(X_oot, y_oot, 32))\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-5653\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = car_classifier.predict(\n",
    "    input_fn=lambda:image_processor_eval_input_fn(X_oot, y_oot, 32))\n",
    "\n",
    "testing_analysis = []\n",
    "\n",
    "for pred, label in zip(predicted_classes, y_oot):\n",
    "    hold = [pred['probabilities'][1], pred['classes'], label[1], pred['logits'][0], pred['logits'][1]]\n",
    "    testing_analysis.append(hold)\n",
    "    \n",
    "testing_analysis = pd.DataFrame(testing_analysis, columns = ['prob', 'class', 'label', 'logit_0', 'logit_1'])\n",
    "testing_analysis['logit_1_decile'] = pd.qcut(testing_analysis.logit_1, 10, labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logit_1_decile  label  class\n",
       "0               0      0        231\n",
       "                1      0         29\n",
       "1               0      0        196\n",
       "                1      0         63\n",
       "2               0      0        160\n",
       "                1      0         97\n",
       "                       1          2\n",
       "3               0      1         82\n",
       "                       0         40\n",
       "                1      1        104\n",
       "                       0         34\n",
       "4               0      1        113\n",
       "                1      1        146\n",
       "5               0      1         68\n",
       "                1      1        191\n",
       "6               0      1         49\n",
       "                1      1        211\n",
       "7               0      1         40\n",
       "                1      1        219\n",
       "8               0      1         30\n",
       "                1      1        229\n",
       "9               0      1         27\n",
       "                1      1        233\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_analysis.groupby(['logit_1_decile', 'label'])['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label  class\n",
       "0      0         627\n",
       "       1         409\n",
       "1      1        1335\n",
       "       0         223\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_analysis.groupby('label')['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in testing_analysis.loc[testing_analysis.logit_1_decile == 3].index[0:20]:\n",
    "    plt.figure()\n",
    "    row = testing_analysis.iloc[i]\n",
    "    plt.title('class %f label %f'%(row['class'], row['label']))\n",
    "    imshow(Image.fromarray((X_oot[i,:].reshape((200,200))).astype('uint8'), mode = 'L'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(\n",
    "     input_fn=lambda:image_processor_train_input_fn(\n",
    "         training_image_processor, X_train, y_train, 32), \n",
    "     max_steps=4100)\n",
    "\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=lambda:image_processor_eval_input_fn(X_train, y_train, 32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    }
   ],
   "source": [
    "evaluate_results = tf.estimator.train_and_evaluate(car_classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    inputs = {\n",
    "        'input' : tf.placeholder(tf.float32, [None, 200, 200, 1]),\n",
    "    }\n",
    "    \n",
    "    inputs['input'] = tf.divide(inputs['input'], 255.0)\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-4100\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/ec2-user/convnet_saved_model/temp-b'1553120111'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'/home/ec2-user/convnet_saved_model/1553120111'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_classifier.export_savedmodel('/home/ec2-user/convnet_saved_model/', serving_input_receiver_fn,\n",
    "                            strip_default_attrs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
