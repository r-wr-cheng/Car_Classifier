{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "#tf.enable_eager_execution()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv('/home/ec2-user/training_data_meta.csv')\n",
    "\n",
    "#Join cleaned class data with training metadata\n",
    "\n",
    "class_data = pd.read_csv('/home/ec2-user/stanford_labels_cleaned.csv')\n",
    "\n",
    "meta_data = pd.merge(meta_data, class_data, on = 'class', how = 'left')\n",
    "\n",
    "meta_data = meta_data.loc[meta_data['Body Type'].isin(['Coupe', 'Sedan'])].copy()\n",
    "\n",
    "meta_data['is_sedan_target'] = (meta_data['Body Type'] == 'Sedan').astype(int)\n",
    "\n",
    "image_dict = p.load(open('/home/ec2-user/scaled_bounded_grayscale_dict.p', 'rb'))\n",
    "\n",
    "training_data = []\n",
    "for i in meta_data[['is_sedan_target', 'fname']].iterrows():\n",
    "    row = [i[1]['is_sedan_target']]\n",
    "    row.extend(image_dict[i[1]['fname']].flatten())\n",
    "    training_data.append(row)\n",
    "\n",
    "training_data = np.array(training_data).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_data[:,1:], \n",
    "                                                    training_data[:,0], \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=420)\n",
    "\n",
    "y_train = y_train.astype('int32')\n",
    "y_test = y_test.astype('int32')\n",
    "\n",
    "negatives = []\n",
    "for ind, elem in enumerate(y_train):\n",
    "    if elem == 0:\n",
    "        negatives.append(ind)\n",
    "np.random.shuffle(negatives)\n",
    "\n",
    "neg_dupe_target = 2 * y_train.sum() - y_train.shape[0]\n",
    "\n",
    "X_train = np.concatenate([X_train, X_train[negatives[0:neg_dupe_target],:]],\n",
    "                         axis = 0\n",
    "                        )\n",
    "y_train = np.concatenate([y_train, y_train[negatives[0:neg_dupe_target]]],\n",
    "                         axis = 0\n",
    "                        )\n",
    "\n",
    "y_train = np.concatenate([1 - y_train.reshape(-1,1), y_train.reshape(-1,1)], axis = 1)\n",
    "y_test = np.concatenate([1 - y_test.reshape(-1,1), y_test.reshape(-1,1)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    if type(features) is dict:\n",
    "        features = features['input']\n",
    "    #Define model architecture\n",
    "    \n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    input_layer = tf.reshape(features, [-1, 200, 200, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Computes 32 features using a 3x3 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 200, 200, 1]\n",
    "    # Output Tensor Shape: [batch_size, 200, 200, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 200, 200, 32]\n",
    "    # Output Tensor Shape: [batch_size, 100, 100, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Computes 64 features using a 3x3 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 100, 100, 32]\n",
    "    # Output Tensor Shape: [batch_size, 100, 100, 64]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 100, 100, 64]\n",
    "    # Output Tensor Shape: [batch_size, 50, 50, 64]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "      inputs=pool2,\n",
    "      filters=64,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #3\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 50, 50, 64]\n",
    "    # Output Tensor Shape: [batch_size, 25, 25, 64]\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 25, 25, 64]\n",
    "    # Output Tensor Shape: [batch_size, 25 * 25 * 64]\n",
    "    pool3_flat = tf.reshape(pool3, [-1, 25 * 25 * 64])\n",
    "\n",
    "    # Dense Layer\n",
    "    # Densely connected layer with 256 neurons\n",
    "    # Input Tensor Shape: [batch_size, 25 * 25 * 64]\n",
    "    # Output Tensor Shape: [batch_size, 256]\n",
    "    dense = tf.layers.dense(inputs=pool3_flat, units=64, activation=tf.nn.relu)\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.75, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=2)\n",
    "    \n",
    "    #Predict Op\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            # Generate predictions (for PREDICT and EVAL mode)\n",
    "            \"classes\": tf.argmax(input=logits, axis=1),\n",
    "            # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "            # `logging_hook`.\n",
    "            \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\"),\n",
    "            \"logits\" : logits\n",
    "            \n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #Define model outputs\n",
    "        # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels[:,1], logits=logits)\n",
    "        \n",
    "        logging_hook = tf.train.LoggingTensorHook(\n",
    "            {\"loss\" : loss,\n",
    "            },\n",
    "            every_n_iter=10)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss, train_op=train_op, training_hooks = [logging_hook])\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        #Define model outputs\n",
    "        # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels[:,1], logits=logits)\n",
    "        \n",
    "        predictions = {\n",
    "          # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "          # `logging_hook`.\n",
    "          \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "        }\n",
    "        #swap this for AUROC?\n",
    "        eval_metric_ops = {\n",
    "          \"eval_accuracy\": tf.metrics.auc(\n",
    "              labels=labels, predictions=predictions[\"probabilities\"])}\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "          mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/home/ec2-user/convnet_model', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 32\n",
      "inter_op_parallelism_threads: 32\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f22cb44bcf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "session_config = tf.ConfigProto(\n",
    "      inter_op_parallelism_threads=32,\n",
    "      intra_op_parallelism_threads=32,\n",
    "      )\n",
    "\n",
    "config = tf.estimator.RunConfig(session_config = session_config,\n",
    "                                log_step_count_steps = 10,\n",
    "                                save_summary_steps = 10\n",
    "                               )\n",
    "\n",
    "# Create the Estimator\n",
    "car_classifier = tf.estimator.Estimator(\n",
    "  model_fn=cnn_model_fn, model_dir=\"/home/ec2-user/convnet_model\", config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom input function using training_image_processor with tf.data.Dataset\n",
    "def image_processor_train_input_fn(image_processor, X_train, y_train, batch_size):\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator = lambda : image_processor.flow(X_train.reshape((X_train.shape[0], 200, 200, 1)), \n",
    "                                                  y_train, batch_size, shuffle = True), \n",
    "        output_types = (np.float32, np.int32))\n",
    "    \n",
    "    dataset = dataset.shuffle(512).repeat()\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def image_processor_eval_input_fn(X_test, y_test, batch_size):\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_test.astype('float32') / 255.0, \n",
    "                                                  y_test.astype('int32')))\n",
    "        \n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "#Shearing, no zooming\n",
    "training_image_processor = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    shear_range=15,\n",
    "    horizontal_flip=True,\n",
    "    data_format = 'channels_last',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-4-5d33d258b2d0>:21: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-5d33d258b2d0>:27: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-5d33d258b2d0>:69: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-5d33d258b2d0>:73: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.7053856, step = 1\n",
      "INFO:tensorflow:loss = 0.7053856\n",
      "INFO:tensorflow:global_step/sec: 0.285473\n",
      "INFO:tensorflow:loss = 0.6922831, step = 11 (35.031 sec)\n",
      "INFO:tensorflow:loss = 0.6922831 (35.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302661\n",
      "INFO:tensorflow:loss = 0.6938073, step = 21 (33.040 sec)\n",
      "INFO:tensorflow:loss = 0.6938073 (33.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.31311\n",
      "INFO:tensorflow:loss = 0.6931003, step = 31 (31.937 sec)\n",
      "INFO:tensorflow:loss = 0.6931003 (31.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301324\n",
      "INFO:tensorflow:loss = 0.69138217, step = 41 (33.187 sec)\n",
      "INFO:tensorflow:loss = 0.69138217 (33.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300775\n",
      "INFO:tensorflow:loss = 0.6924108, step = 51 (33.247 sec)\n",
      "INFO:tensorflow:loss = 0.6924108 (33.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30136\n",
      "INFO:tensorflow:loss = 0.6932795, step = 61 (33.183 sec)\n",
      "INFO:tensorflow:loss = 0.6932795 (33.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30264\n",
      "INFO:tensorflow:loss = 0.6933534, step = 71 (33.043 sec)\n",
      "INFO:tensorflow:loss = 0.6933534 (33.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300014\n",
      "INFO:tensorflow:loss = 0.6909936, step = 81 (33.332 sec)\n",
      "INFO:tensorflow:loss = 0.6909936 (33.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.303127\n",
      "INFO:tensorflow:loss = 0.6941375, step = 91 (32.990 sec)\n",
      "INFO:tensorflow:loss = 0.6941375 (32.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301737\n",
      "INFO:tensorflow:loss = 0.6931539, step = 101 (33.141 sec)\n",
      "INFO:tensorflow:loss = 0.6931539 (33.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.33838\n",
      "INFO:tensorflow:loss = 0.6886641, step = 141 (29.553 sec)\n",
      "INFO:tensorflow:loss = 0.6886641 (29.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.297529\n",
      "INFO:tensorflow:loss = 0.6891546, step = 151 (33.610 sec)\n",
      "INFO:tensorflow:loss = 0.6891546 (33.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.306369\n",
      "INFO:tensorflow:loss = 0.6915697, step = 161 (32.641 sec)\n",
      "INFO:tensorflow:loss = 0.6915697 (32.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.312528\n",
      "INFO:tensorflow:loss = 0.69107336, step = 171 (31.997 sec)\n",
      "INFO:tensorflow:loss = 0.69107336 (31.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301889\n",
      "INFO:tensorflow:loss = 0.69051325, step = 181 (33.125 sec)\n",
      "INFO:tensorflow:loss = 0.69051325 (33.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302011\n",
      "INFO:tensorflow:loss = 0.69451725, step = 191 (33.111 sec)\n",
      "INFO:tensorflow:loss = 0.69451725 (33.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300806\n",
      "INFO:tensorflow:loss = 0.6904535, step = 201 (33.244 sec)\n",
      "INFO:tensorflow:loss = 0.6904535 (33.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302257\n",
      "INFO:tensorflow:loss = 0.68308854, step = 211 (33.084 sec)\n",
      "INFO:tensorflow:loss = 0.68308854 (33.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301695\n",
      "INFO:tensorflow:loss = 0.67646086, step = 221 (33.146 sec)\n",
      "INFO:tensorflow:loss = 0.67646086 (33.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300287\n",
      "INFO:tensorflow:loss = 0.6854223, step = 231 (33.302 sec)\n",
      "INFO:tensorflow:loss = 0.6854223 (33.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.299697\n",
      "INFO:tensorflow:loss = 0.6720085, step = 241 (33.367 sec)\n",
      "INFO:tensorflow:loss = 0.6720085 (33.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30149\n",
      "INFO:tensorflow:loss = 0.67079353, step = 251 (33.169 sec)\n",
      "INFO:tensorflow:loss = 0.67079353 (33.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.298778\n",
      "INFO:tensorflow:loss = 0.68448424, step = 261 (33.469 sec)\n",
      "INFO:tensorflow:loss = 0.68448424 (33.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301833\n",
      "INFO:tensorflow:loss = 0.71069956, step = 271 (33.131 sec)\n",
      "INFO:tensorflow:loss = 0.71069956 (33.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302117\n",
      "INFO:tensorflow:loss = 0.6928468, step = 281 (33.100 sec)\n",
      "INFO:tensorflow:loss = 0.6928468 (33.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.299928\n",
      "INFO:tensorflow:loss = 0.70048887, step = 291 (33.341 sec)\n",
      "INFO:tensorflow:loss = 0.70048887 (33.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302307\n",
      "INFO:tensorflow:loss = 0.6823346, step = 301 (33.079 sec)\n",
      "INFO:tensorflow:loss = 0.6823346 (33.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.312438\n",
      "INFO:tensorflow:loss = 0.6778016, step = 311 (32.006 sec)\n",
      "INFO:tensorflow:loss = 0.6778016 (32.006 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 320 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.313775\n",
      "INFO:tensorflow:loss = 0.66109896, step = 321 (31.870 sec)\n",
      "INFO:tensorflow:loss = 0.66109896 (31.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300534\n",
      "INFO:tensorflow:loss = 0.67541987, step = 331 (33.274 sec)\n",
      "INFO:tensorflow:loss = 0.67541987 (33.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.313519\n",
      "INFO:tensorflow:loss = 0.6534126, step = 341 (31.896 sec)\n",
      "INFO:tensorflow:loss = 0.6534126 (31.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301762\n",
      "INFO:tensorflow:loss = 0.65289867, step = 351 (33.138 sec)\n",
      "INFO:tensorflow:loss = 0.65289867 (33.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.312319\n",
      "INFO:tensorflow:loss = 0.67773044, step = 361 (32.019 sec)\n",
      "INFO:tensorflow:loss = 0.67773044 (32.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30288\n",
      "INFO:tensorflow:loss = 0.68127286, step = 371 (33.016 sec)\n",
      "INFO:tensorflow:loss = 0.68127286 (33.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.313603\n",
      "INFO:tensorflow:loss = 0.6884972, step = 381 (31.887 sec)\n",
      "INFO:tensorflow:loss = 0.6884972 (31.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.314329\n",
      "INFO:tensorflow:loss = 0.66580325, step = 391 (31.814 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.66580325 (31.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300105\n",
      "INFO:tensorflow:loss = 0.6723617, step = 401 (33.322 sec)\n",
      "INFO:tensorflow:loss = 0.6723617 (33.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30254\n",
      "INFO:tensorflow:loss = 0.6870371, step = 411 (33.053 sec)\n",
      "INFO:tensorflow:loss = 0.6870371 (33.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300591\n",
      "INFO:tensorflow:loss = 0.65770775, step = 421 (33.268 sec)\n",
      "INFO:tensorflow:loss = 0.65770775 (33.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.312922\n",
      "INFO:tensorflow:loss = 0.6437076, step = 431 (31.957 sec)\n",
      "INFO:tensorflow:loss = 0.6437076 (31.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302739\n",
      "INFO:tensorflow:loss = 0.6737777, step = 441 (33.032 sec)\n",
      "INFO:tensorflow:loss = 0.6737777 (33.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.31089\n",
      "INFO:tensorflow:loss = 0.6607775, step = 451 (32.165 sec)\n",
      "INFO:tensorflow:loss = 0.6607775 (32.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.313419\n",
      "INFO:tensorflow:loss = 0.70124847, step = 461 (31.906 sec)\n",
      "INFO:tensorflow:loss = 0.70124847 (31.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30223\n",
      "INFO:tensorflow:loss = 0.662046, step = 471 (33.087 sec)\n",
      "INFO:tensorflow:loss = 0.662046 (33.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.313022\n",
      "INFO:tensorflow:loss = 0.6591567, step = 481 (31.947 sec)\n",
      "INFO:tensorflow:loss = 0.6591567 (31.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302276\n",
      "INFO:tensorflow:loss = 0.6769764, step = 491 (33.082 sec)\n",
      "INFO:tensorflow:loss = 0.6769764 (33.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.314442\n",
      "INFO:tensorflow:loss = 0.61381495, step = 501 (31.802 sec)\n",
      "INFO:tensorflow:loss = 0.61381495 (31.802 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 505 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.300273\n",
      "INFO:tensorflow:loss = 0.6653276, step = 511 (33.305 sec)\n",
      "INFO:tensorflow:loss = 0.6653276 (33.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301627\n",
      "INFO:tensorflow:loss = 0.6800531, step = 521 (33.152 sec)\n",
      "INFO:tensorflow:loss = 0.6800531 (33.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.315297\n",
      "INFO:tensorflow:loss = 0.6730768, step = 531 (31.716 sec)\n",
      "INFO:tensorflow:loss = 0.6730768 (31.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.324176\n",
      "INFO:tensorflow:loss = 0.71031314, step = 541 (30.848 sec)\n",
      "INFO:tensorflow:loss = 0.71031314 (30.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.31393\n",
      "INFO:tensorflow:loss = 0.6864531, step = 551 (31.854 sec)\n",
      "INFO:tensorflow:loss = 0.6864531 (31.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301374\n",
      "INFO:tensorflow:loss = 0.638527, step = 561 (33.181 sec)\n",
      "INFO:tensorflow:loss = 0.638527 (33.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30201\n",
      "INFO:tensorflow:loss = 0.6472814, step = 571 (33.111 sec)\n",
      "INFO:tensorflow:loss = 0.6472814 (33.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300849\n",
      "INFO:tensorflow:loss = 0.6563512, step = 581 (33.239 sec)\n",
      "INFO:tensorflow:loss = 0.6563512 (33.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.3001\n",
      "INFO:tensorflow:loss = 0.63853216, step = 591 (33.322 sec)\n",
      "INFO:tensorflow:loss = 0.63853216 (33.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301879\n",
      "INFO:tensorflow:loss = 0.61833006, step = 601 (33.126 sec)\n",
      "INFO:tensorflow:loss = 0.61833006 (33.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.29997\n",
      "INFO:tensorflow:loss = 0.6671891, step = 611 (33.337 sec)\n",
      "INFO:tensorflow:loss = 0.6671891 (33.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.303257\n",
      "INFO:tensorflow:loss = 0.66790587, step = 621 (32.975 sec)\n",
      "INFO:tensorflow:loss = 0.66790587 (32.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301021\n",
      "INFO:tensorflow:loss = 0.6269304, step = 631 (33.220 sec)\n",
      "INFO:tensorflow:loss = 0.6269304 (33.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.292252\n",
      "INFO:tensorflow:loss = 0.67657614, step = 641 (34.217 sec)\n",
      "INFO:tensorflow:loss = 0.67657614 (34.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.299495\n",
      "INFO:tensorflow:loss = 0.7446847, step = 651 (33.389 sec)\n",
      "INFO:tensorflow:loss = 0.7446847 (33.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.313022\n",
      "INFO:tensorflow:loss = 0.6517777, step = 661 (31.947 sec)\n",
      "INFO:tensorflow:loss = 0.6517777 (31.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.326081\n",
      "INFO:tensorflow:loss = 0.6500204, step = 671 (30.667 sec)\n",
      "INFO:tensorflow:loss = 0.6500204 (30.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.312101\n",
      "INFO:tensorflow:loss = 0.6137967, step = 681 (32.041 sec)\n",
      "INFO:tensorflow:loss = 0.6137967 (32.041 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 689 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.301517\n",
      "INFO:tensorflow:loss = 0.6459186, step = 691 (33.166 sec)\n",
      "INFO:tensorflow:loss = 0.6459186 (33.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301334\n",
      "INFO:tensorflow:loss = 0.60980546, step = 701 (33.186 sec)\n",
      "INFO:tensorflow:loss = 0.60980546 (33.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.314116\n",
      "INFO:tensorflow:loss = 0.6287738, step = 711 (31.835 sec)\n",
      "INFO:tensorflow:loss = 0.6287738 (31.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302013\n",
      "INFO:tensorflow:loss = 0.6401011, step = 721 (33.111 sec)\n",
      "INFO:tensorflow:loss = 0.6401011 (33.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.313804\n",
      "INFO:tensorflow:loss = 0.69943315, step = 731 (31.867 sec)\n",
      "INFO:tensorflow:loss = 0.69943315 (31.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30182\n",
      "INFO:tensorflow:loss = 0.656137, step = 741 (33.132 sec)\n",
      "INFO:tensorflow:loss = 0.656137 (33.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301316\n",
      "INFO:tensorflow:loss = 0.62340087, step = 751 (33.188 sec)\n",
      "INFO:tensorflow:loss = 0.62340087 (33.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.314201\n",
      "INFO:tensorflow:loss = 0.616315, step = 761 (31.827 sec)\n",
      "INFO:tensorflow:loss = 0.616315 (31.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.325781\n",
      "INFO:tensorflow:loss = 0.6629756, step = 771 (30.695 sec)\n",
      "INFO:tensorflow:loss = 0.6629756 (30.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.314972\n",
      "INFO:tensorflow:loss = 0.7572259, step = 781 (31.749 sec)\n",
      "INFO:tensorflow:loss = 0.7572259 (31.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.326373\n",
      "INFO:tensorflow:loss = 0.625286, step = 791 (30.640 sec)\n",
      "INFO:tensorflow:loss = 0.625286 (30.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.303624\n",
      "INFO:tensorflow:loss = 0.64244777, step = 801 (32.936 sec)\n",
      "INFO:tensorflow:loss = 0.64244777 (32.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.311575\n",
      "INFO:tensorflow:loss = 0.60597193, step = 811 (32.095 sec)\n",
      "INFO:tensorflow:loss = 0.60597193 (32.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300103\n",
      "INFO:tensorflow:loss = 0.6301327, step = 821 (33.322 sec)\n",
      "INFO:tensorflow:loss = 0.6301327 (33.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30135\n",
      "INFO:tensorflow:loss = 0.6488682, step = 831 (33.184 sec)\n",
      "INFO:tensorflow:loss = 0.6488682 (33.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.299076\n",
      "INFO:tensorflow:loss = 0.5939384, step = 841 (33.436 sec)\n",
      "INFO:tensorflow:loss = 0.5939384 (33.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300334\n",
      "INFO:tensorflow:loss = 0.63954616, step = 851 (33.296 sec)\n",
      "INFO:tensorflow:loss = 0.63954616 (33.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300764\n",
      "INFO:tensorflow:loss = 0.63367224, step = 861 (33.249 sec)\n",
      "INFO:tensorflow:loss = 0.63367224 (33.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302932\n",
      "INFO:tensorflow:loss = 0.67264575, step = 871 (33.011 sec)\n",
      "INFO:tensorflow:loss = 0.67264575 (33.011 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 874 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:global_step/sec: 0.299958\n",
      "INFO:tensorflow:loss = 0.6721211, step = 881 (33.338 sec)\n",
      "INFO:tensorflow:loss = 0.6721211 (33.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.299922\n",
      "INFO:tensorflow:loss = 0.62676805, step = 891 (33.342 sec)\n",
      "INFO:tensorflow:loss = 0.62676805 (33.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300935\n",
      "INFO:tensorflow:loss = 0.6781541, step = 901 (33.230 sec)\n",
      "INFO:tensorflow:loss = 0.6781541 (33.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.29981\n",
      "INFO:tensorflow:loss = 0.6209248, step = 911 (33.354 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6209248 (33.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.31469\n",
      "INFO:tensorflow:loss = 0.60890234, step = 921 (31.777 sec)\n",
      "INFO:tensorflow:loss = 0.60890234 (31.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300784\n",
      "INFO:tensorflow:loss = 0.6235567, step = 931 (33.246 sec)\n",
      "INFO:tensorflow:loss = 0.6235567 (33.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302319\n",
      "INFO:tensorflow:loss = 0.6055093, step = 941 (33.078 sec)\n",
      "INFO:tensorflow:loss = 0.6055093 (33.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300541\n",
      "INFO:tensorflow:loss = 0.609431, step = 951 (33.273 sec)\n",
      "INFO:tensorflow:loss = 0.609431 (33.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301323\n",
      "INFO:tensorflow:loss = 0.62763244, step = 961 (33.187 sec)\n",
      "INFO:tensorflow:loss = 0.62763244 (33.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.310594\n",
      "INFO:tensorflow:loss = 0.6142158, step = 971 (32.196 sec)\n",
      "INFO:tensorflow:loss = 0.6142158 (32.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301077\n",
      "INFO:tensorflow:loss = 0.6136466, step = 981 (33.214 sec)\n",
      "INFO:tensorflow:loss = 0.6136466 (33.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30451\n",
      "INFO:tensorflow:loss = 0.6355822, step = 991 (32.840 sec)\n",
      "INFO:tensorflow:loss = 0.6355822 (32.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300917\n",
      "INFO:tensorflow:loss = 0.604933, step = 1001 (33.232 sec)\n",
      "INFO:tensorflow:loss = 0.604933 (33.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.326913\n",
      "INFO:tensorflow:loss = 0.60323524, step = 1011 (30.589 sec)\n",
      "INFO:tensorflow:loss = 0.60323524 (30.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301084\n",
      "INFO:tensorflow:loss = 0.6216708, step = 1021 (33.213 sec)\n",
      "INFO:tensorflow:loss = 0.6216708 (33.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.312893\n",
      "INFO:tensorflow:loss = 0.62128335, step = 1031 (31.960 sec)\n",
      "INFO:tensorflow:loss = 0.62128335 (31.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301718\n",
      "INFO:tensorflow:loss = 0.6173804, step = 1041 (33.144 sec)\n",
      "INFO:tensorflow:loss = 0.6173804 (33.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.31203\n",
      "INFO:tensorflow:loss = 0.57263553, step = 1051 (32.048 sec)\n",
      "INFO:tensorflow:loss = 0.57263553 (32.048 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1058 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.313208\n",
      "INFO:tensorflow:loss = 0.66207707, step = 1061 (31.928 sec)\n",
      "INFO:tensorflow:loss = 0.66207707 (31.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300214\n",
      "INFO:tensorflow:loss = 0.59020656, step = 1071 (33.309 sec)\n",
      "INFO:tensorflow:loss = 0.59020656 (33.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301569\n",
      "INFO:tensorflow:loss = 0.5772669, step = 1081 (33.160 sec)\n",
      "INFO:tensorflow:loss = 0.5772669 (33.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.309698\n",
      "INFO:tensorflow:loss = 0.5790079, step = 1091 (32.289 sec)\n",
      "INFO:tensorflow:loss = 0.5790079 (32.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300332\n",
      "INFO:tensorflow:loss = 0.55319434, step = 1101 (33.297 sec)\n",
      "INFO:tensorflow:loss = 0.55319434 (33.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.299374\n",
      "INFO:tensorflow:loss = 0.6311327, step = 1111 (33.403 sec)\n",
      "INFO:tensorflow:loss = 0.6311327 (33.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.311759\n",
      "INFO:tensorflow:loss = 0.6173632, step = 1121 (32.076 sec)\n",
      "INFO:tensorflow:loss = 0.6173632 (32.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300563\n",
      "INFO:tensorflow:loss = 0.63815176, step = 1131 (33.271 sec)\n",
      "INFO:tensorflow:loss = 0.63815176 (33.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30038\n",
      "INFO:tensorflow:loss = 0.59938586, step = 1141 (33.291 sec)\n",
      "INFO:tensorflow:loss = 0.59938586 (33.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.314279\n",
      "INFO:tensorflow:loss = 0.5856079, step = 1151 (31.819 sec)\n",
      "INFO:tensorflow:loss = 0.5856079 (31.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.31311\n",
      "INFO:tensorflow:loss = 0.60117793, step = 1161 (31.938 sec)\n",
      "INFO:tensorflow:loss = 0.60117793 (31.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.313671\n",
      "INFO:tensorflow:loss = 0.57807946, step = 1171 (31.880 sec)\n",
      "INFO:tensorflow:loss = 0.57807946 (31.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301136\n",
      "INFO:tensorflow:loss = 0.5968981, step = 1181 (33.208 sec)\n",
      "INFO:tensorflow:loss = 0.5968981 (33.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302062\n",
      "INFO:tensorflow:loss = 0.58440435, step = 1191 (33.105 sec)\n",
      "INFO:tensorflow:loss = 0.58440435 (33.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.31167\n",
      "INFO:tensorflow:loss = 0.58479774, step = 1201 (32.086 sec)\n",
      "INFO:tensorflow:loss = 0.58479774 (32.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300573\n",
      "INFO:tensorflow:loss = 0.5792868, step = 1211 (33.270 sec)\n",
      "INFO:tensorflow:loss = 0.5792868 (33.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.313714\n",
      "INFO:tensorflow:loss = 0.62347704, step = 1221 (31.876 sec)\n",
      "INFO:tensorflow:loss = 0.62347704 (31.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.311734\n",
      "INFO:tensorflow:loss = 0.6578671, step = 1231 (32.079 sec)\n",
      "INFO:tensorflow:loss = 0.6578671 (32.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.303279\n",
      "INFO:tensorflow:loss = 0.5708916, step = 1241 (32.973 sec)\n",
      "INFO:tensorflow:loss = 0.5708916 (32.973 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1242 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.312841\n",
      "INFO:tensorflow:loss = 0.5610994, step = 1251 (31.965 sec)\n",
      "INFO:tensorflow:loss = 0.5610994 (31.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.303107\n",
      "INFO:tensorflow:loss = 0.59800303, step = 1261 (32.992 sec)\n",
      "INFO:tensorflow:loss = 0.59800303 (32.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.299929\n",
      "INFO:tensorflow:loss = 0.6146878, step = 1271 (33.341 sec)\n",
      "INFO:tensorflow:loss = 0.6146878 (33.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30115\n",
      "INFO:tensorflow:loss = 0.55422616, step = 1281 (33.206 sec)\n",
      "INFO:tensorflow:loss = 0.55422616 (33.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.312788\n",
      "INFO:tensorflow:loss = 0.60384846, step = 1291 (31.970 sec)\n",
      "INFO:tensorflow:loss = 0.60384846 (31.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301918\n",
      "INFO:tensorflow:loss = 0.5465987, step = 1301 (33.121 sec)\n",
      "INFO:tensorflow:loss = 0.5465987 (33.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.302355\n",
      "INFO:tensorflow:loss = 0.56207025, step = 1311 (33.074 sec)\n",
      "INFO:tensorflow:loss = 0.56207025 (33.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301141\n",
      "INFO:tensorflow:loss = 0.5929971, step = 1321 (33.207 sec)\n",
      "INFO:tensorflow:loss = 0.5929971 (33.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301872\n",
      "INFO:tensorflow:loss = 0.63944423, step = 1331 (33.127 sec)\n",
      "INFO:tensorflow:loss = 0.63944423 (33.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.312588\n",
      "INFO:tensorflow:loss = 0.5938796, step = 1341 (31.991 sec)\n",
      "INFO:tensorflow:loss = 0.5938796 (31.991 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.301375\n",
      "INFO:tensorflow:loss = 0.56650454, step = 1351 (33.181 sec)\n",
      "INFO:tensorflow:loss = 0.56650454 (33.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.298983\n",
      "INFO:tensorflow:loss = 0.6181106, step = 1361 (33.447 sec)\n",
      "INFO:tensorflow:loss = 0.6181106 (33.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.299238\n",
      "INFO:tensorflow:loss = 0.62796485, step = 1371 (33.418 sec)\n",
      "INFO:tensorflow:loss = 0.62796485 (33.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.314516\n",
      "INFO:tensorflow:loss = 0.61576724, step = 1381 (31.795 sec)\n",
      "INFO:tensorflow:loss = 0.61576724 (31.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.312091\n",
      "INFO:tensorflow:loss = 0.60270786, step = 1391 (32.042 sec)\n",
      "INFO:tensorflow:loss = 0.60270786 (32.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.3123\n",
      "INFO:tensorflow:loss = 0.57717335, step = 1401 (32.021 sec)\n",
      "INFO:tensorflow:loss = 0.57717335 (32.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.312806\n",
      "INFO:tensorflow:loss = 0.5586362, step = 1411 (31.969 sec)\n",
      "INFO:tensorflow:loss = 0.5586362 (31.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.314407\n",
      "INFO:tensorflow:loss = 0.5800711, step = 1421 (31.806 sec)\n",
      "INFO:tensorflow:loss = 0.5800711 (31.806 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1426 into /home/ec2-user/convnet_model/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.300347\n",
      "INFO:tensorflow:loss = 0.5266615, step = 1431 (33.295 sec)\n",
      "INFO:tensorflow:loss = 0.5266615 (33.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300189\n",
      "INFO:tensorflow:loss = 0.6429612, step = 1441 (33.312 sec)\n",
      "INFO:tensorflow:loss = 0.6429612 (33.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.30097\n",
      "INFO:tensorflow:loss = 0.5908797, step = 1451 (33.226 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5908797 (33.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.324866\n",
      "INFO:tensorflow:loss = 0.50253683, step = 1461 (30.782 sec)\n",
      "INFO:tensorflow:loss = 0.50253683 (30.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.303008\n",
      "INFO:tensorflow:loss = 0.5550585, step = 1471 (33.002 sec)\n",
      "INFO:tensorflow:loss = 0.5550585 (33.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300101\n",
      "INFO:tensorflow:loss = 0.5309864, step = 1481 (33.322 sec)\n",
      "INFO:tensorflow:loss = 0.5309864 (33.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.311875\n",
      "INFO:tensorflow:loss = 0.53979576, step = 1491 (32.064 sec)\n",
      "INFO:tensorflow:loss = 0.53979576 (32.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.312579\n",
      "INFO:tensorflow:loss = 0.527153, step = 1501 (31.992 sec)\n",
      "INFO:tensorflow:loss = 0.527153 (31.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300147\n",
      "INFO:tensorflow:loss = 0.5353063, step = 1511 (33.317 sec)\n",
      "INFO:tensorflow:loss = 0.5353063 (33.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.312641\n",
      "INFO:tensorflow:loss = 0.554842, step = 1521 (31.986 sec)\n",
      "INFO:tensorflow:loss = 0.554842 (31.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.300426\n",
      "INFO:tensorflow:loss = 0.6092384, step = 1531 (33.286 sec)\n",
      "INFO:tensorflow:loss = 0.6092384 (33.286 sec)\n"
     ]
    }
   ],
   "source": [
    "car_classifier.train(\n",
    "      input_fn=lambda:image_processor_train_input_fn(training_image_processor, X_train, y_train, 128),\n",
    "      steps=5000\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-4-5d33d258b2d0>:21: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-5d33d258b2d0>:27: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-5d33d258b2d0>:69: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-5d33d258b2d0>:73: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-21T22:50:15Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-21-22:51:02\n",
      "INFO:tensorflow:Saving dict for global step 5000: eval_accuracy = 0.94837123, global_step = 5000, loss = 0.28858632\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /home/ec2-user/convnet_model/model.ckpt-5000\n",
      "{'eval_accuracy': 0.94837123, 'loss': 0.28858632, 'global_step': 5000}\n",
      "testing error\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-21T22:51:07Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-21-22:51:24\n",
      "INFO:tensorflow:Saving dict for global step 5000: eval_accuracy = 0.85569066, global_step = 5000, loss = 0.5349732\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /home/ec2-user/convnet_model/model.ckpt-5000\n",
      "{'eval_accuracy': 0.85569066, 'loss': 0.5349732, 'global_step': 5000}\n"
     ]
    }
   ],
   "source": [
    "print('training error')\n",
    "eval_results = car_classifier.evaluate(\n",
    "    input_fn=lambda:image_processor_eval_input_fn(X_train, y_train, 32))\n",
    "print(eval_results)\n",
    "\n",
    "print('testing error')\n",
    "eval_results = car_classifier.evaluate(\n",
    "    input_fn=lambda:image_processor_eval_input_fn(X_test, y_test, 32))\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-5653\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = car_classifier.predict(\n",
    "    input_fn=lambda:image_processor_eval_input_fn(X_test, y_test, 32))\n",
    "\n",
    "testing_analysis = []\n",
    "\n",
    "for pred, label in zip(predicted_classes, y_test):\n",
    "    hold = [pred['probabilities'][1], pred['classes'], label[1], pred['logits'][0], pred['logits'][1]]\n",
    "    testing_analysis.append(hold)\n",
    "    \n",
    "testing_analysis = pd.DataFrame(testing_analysis, columns = ['prob', 'class', 'label', 'logit_0', 'logit_1'])\n",
    "testing_analysis['logit_1_decile'] = pd.qcut(testing_analysis.logit_1, 10, labels = False)\n",
    "testing_analysis['logit_0_decile'] = pd.qcut(testing_analysis.logit_0, 10, labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logit_1_decile  label  class\n",
       "0               0      0        103\n",
       "                1      0          6\n",
       "1               0      0         90\n",
       "                1      0         18\n",
       "2               0      0         82\n",
       "                1      0         27\n",
       "3               0      0         66\n",
       "                1      0         42\n",
       "4               0      0         28\n",
       "                       1         27\n",
       "                1      1         37\n",
       "                       0         17\n",
       "5               0      1         21\n",
       "                1      1         87\n",
       "6               0      1         13\n",
       "                1      1         95\n",
       "7               0      1         13\n",
       "                1      1         96\n",
       "8               0      1          8\n",
       "                1      1        100\n",
       "9               0      1          5\n",
       "                1      1        104\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_analysis.groupby(['logit_1_decile', 'label'])['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logit_0_decile  label  class\n",
       "0               0      1          3\n",
       "                1      1        106\n",
       "1               0      1          9\n",
       "                1      1         99\n",
       "2               0      1         13\n",
       "                1      1         96\n",
       "3               0      1         12\n",
       "                1      1         96\n",
       "4               0      1         25\n",
       "                       0          1\n",
       "                1      1         81\n",
       "                       0          2\n",
       "5               0      0         26\n",
       "                       1         25\n",
       "                1      1         39\n",
       "                       0         18\n",
       "6               0      0         71\n",
       "                1      0         35\n",
       "                       1          2\n",
       "7               0      0         77\n",
       "                1      0         32\n",
       "8               0      0         92\n",
       "                1      0         16\n",
       "9               0      0        102\n",
       "                1      0          7\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_analysis.groupby(['logit_0_decile', 'label'])['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label  class\n",
       "0      0        369\n",
       "       1         87\n",
       "1      1        519\n",
       "       0        110\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_analysis.groupby('label')['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in testing_analysis.loc[testing_analysis.logit_1_decile == 9].index[0:20]:\n",
    "    plt.figure()\n",
    "    row = testing_analysis.iloc[i]\n",
    "    plt.title('class %f label %f'%(row['class'], row['label']))\n",
    "    imshow(Image.fromarray((X_test[i,:].reshape((200,200))).astype('uint8'), mode = 'L'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUVs and Verts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv('/home/ec2-user/training_data_meta.csv')\n",
    "\n",
    "#Join cleaned class data with training metadata\n",
    "\n",
    "class_data = pd.read_csv('/home/ec2-user/stanford_labels_cleaned.csv')\n",
    "\n",
    "meta_data = pd.merge(meta_data, class_data, on = 'class', how = 'left')\n",
    "\n",
    "meta_data = meta_data.loc[meta_data['Body Type'].isin(['SUV', 'Convertible'\n",
    "                                                      ])].copy()\n",
    "\n",
    "meta_data['is_sedan_target'] = (meta_data['Body Type'] == 'SUV').astype(int)\n",
    "\n",
    "image_dict = p.load(open('/home/ec2-user/scaled_bounded_grayscale_dict.p', 'rb'))\n",
    "\n",
    "oot_data = []\n",
    "for i in meta_data[['is_sedan_target', 'fname']].iterrows():\n",
    "    row = [i[1]['is_sedan_target']]\n",
    "    row.extend(image_dict[i[1]['fname']].flatten())\n",
    "    oot_data.append(row)\n",
    "\n",
    "oot_data = np.array(oot_data).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oot = oot_data[:,1:]\n",
    "\n",
    "y_oot = oot_data[:,0].astype('int32')\n",
    "y_oot = np.concatenate([1 - y_oot.reshape(-1,1), y_oot.reshape(-1,1)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oot error\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-21T15:51:47Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-5653\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-21-15:52:17\n",
      "INFO:tensorflow:Saving dict for global step 5653: eval_accuracy = 0.82551754, global_step = 5653, loss = 0.80654323\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5653: /home/ec2-user/convnet_model/model.ckpt-5653\n",
      "{'eval_accuracy': 0.82551754, 'loss': 0.80654323, 'global_step': 5653}\n"
     ]
    }
   ],
   "source": [
    "print('oot error')\n",
    "eval_results = car_classifier.evaluate(\n",
    "    input_fn=lambda:image_processor_eval_input_fn(X_oot, y_oot, 32))\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-5653\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = car_classifier.predict(\n",
    "    input_fn=lambda:image_processor_eval_input_fn(X_oot, y_oot, 32))\n",
    "\n",
    "testing_analysis = []\n",
    "\n",
    "for pred, label in zip(predicted_classes, y_oot):\n",
    "    hold = [pred['probabilities'][1], pred['classes'], label[1], pred['logits'][0], pred['logits'][1]]\n",
    "    testing_analysis.append(hold)\n",
    "    \n",
    "testing_analysis = pd.DataFrame(testing_analysis, columns = ['prob', 'class', 'label', 'logit_0', 'logit_1'])\n",
    "testing_analysis['logit_1_decile'] = pd.qcut(testing_analysis.logit_1, 10, labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logit_1_decile  label  class\n",
       "0               0      0        231\n",
       "                1      0         29\n",
       "1               0      0        196\n",
       "                1      0         63\n",
       "2               0      0        160\n",
       "                1      0         97\n",
       "                       1          2\n",
       "3               0      1         82\n",
       "                       0         40\n",
       "                1      1        104\n",
       "                       0         34\n",
       "4               0      1        113\n",
       "                1      1        146\n",
       "5               0      1         68\n",
       "                1      1        191\n",
       "6               0      1         49\n",
       "                1      1        211\n",
       "7               0      1         40\n",
       "                1      1        219\n",
       "8               0      1         30\n",
       "                1      1        229\n",
       "9               0      1         27\n",
       "                1      1        233\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_analysis.groupby(['logit_1_decile', 'label'])['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label  class\n",
       "0      0         627\n",
       "       1         409\n",
       "1      1        1335\n",
       "       0         223\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_analysis.groupby('label')['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in testing_analysis.loc[testing_analysis.logit_1_decile == 3].index[0:20]:\n",
    "    plt.figure()\n",
    "    row = testing_analysis.iloc[i]\n",
    "    plt.title('class %f label %f'%(row['class'], row['label']))\n",
    "    imshow(Image.fromarray((X_oot[i,:].reshape((200,200))).astype('uint8'), mode = 'L'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(\n",
    "     input_fn=lambda:image_processor_train_input_fn(\n",
    "         training_image_processor, X_train, y_train, 32), \n",
    "     max_steps=4100)\n",
    "\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=lambda:image_processor_eval_input_fn(X_train, y_train, 32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    }
   ],
   "source": [
    "evaluate_results = tf.estimator.train_and_evaluate(car_classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    inputs = {\n",
    "        'input' : tf.placeholder(tf.float32, [None, 200, 200, 1]),\n",
    "    }\n",
    "    \n",
    "    inputs['input'] = tf.divide(inputs['input'], 255.0)\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from /home/ec2-user/convnet_model/model.ckpt-4100\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/ec2-user/convnet_saved_model/temp-b'1553120111'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'/home/ec2-user/convnet_saved_model/1553120111'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_classifier.export_savedmodel('/home/ec2-user/convnet_saved_model/', serving_input_receiver_fn,\n",
    "                            strip_default_attrs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
